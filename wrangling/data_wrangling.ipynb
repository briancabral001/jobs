{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cd8d854",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os \n",
    "from datasets import load_dataset\n",
    "\n",
    "# üåê Hugging Face Datasets (to download raw data)\n",
    "ds = load_dataset(\"lukebarousse/data_jobs\")\n",
    "\n",
    "# Convert into a pandas DataFrame\n",
    "import pandas as pd\n",
    "df_raw = pd.DataFrame(ds['train'])\n",
    "\n",
    "project_root = os.path.abspath(\"..\") \n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from features.helpers import filter_jobs\n",
    "from features.wrangling import * "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d29cfdd",
   "metadata": {},
   "source": [
    "### üîÑ Data Cleaning: Locations & Job Types\n",
    "\n",
    "This function aims to:\n",
    "\n",
    "1. **Remove duplicates** from the dataset.  \n",
    "2. **Extract the correct country** from the `job_location` column, since there were inconsistencies (e.g., `job_location = \"New York\"` but `job_country = \"Sudan\"`).  \n",
    "3. **Normalize the `job_type` column** using a mapping tool to standardize job categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a4ae416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial rows: 785741\n",
      "Duplicates removed: 101\n",
      "Rows after filtering location: 754305\n",
      "Final rows after normalizing job type: 754305\n"
     ]
    }
   ],
   "source": [
    "def wrangle_country(df):\n",
    "    print(f\"Initial rows: {len(df)}\")\n",
    "    initial_len = len(df)\n",
    "    df = df.drop_duplicates()\n",
    "    print(f\"Duplicates removed: {initial_len - len(df)}\")\n",
    "\n",
    "    df = filter_location_matches_country(df)\n",
    "    print(f\"Rows after filtering location: {len(df)}\")\n",
    "\n",
    "    df = normalize_job_type(df)\n",
    "    print(f\"Final rows after normalizing job type: {len(df)}\")\n",
    "    return df\n",
    "df_clean = wrangle_country(df_raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840a045b",
   "metadata": {},
   "source": [
    "### üßπ Removing Outliers\n",
    "\n",
    "We will remove the outliers identified in the `salary_year_avg` column to ensure a cleaner and more accurate analysis of salaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e570dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = remove_outliers(df_clean) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f123d540",
   "metadata": {},
   "source": [
    "### üíæ Save Cleaned Data\n",
    "\n",
    "Once the data is cleaned, we save it in the `data/clean` folder so it can be used in the **Analysis notebook**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c11436b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado exitosamente en: /Users/brian/Documents/jobs/data/clean/clean_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd # Necesario si df_cleaned es un DataFrame\n",
    "\n",
    "# 1. Define la ruta completa del archivo\n",
    "CLEAN_PATH = \"/Users/brian/Documents/jobs/data/clean/clean_data.csv\"\n",
    "\n",
    "# 2. Extrae solo el directorio (la ruta de la carpeta)\n",
    "# Esto toma: /Users/brian/Documents/data_jobs/data/clean/\n",
    "output_dir = os.path.dirname(CLEAN_PATH)\n",
    "\n",
    "# 3. CREA LA CARPETA si no existe\n",
    "# El argumento 'exist_ok=True' evita un error si la carpeta ya est√° ah√≠.\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 4. Guarda el DataFrame\n",
    "# (Aseg√∫rate de que 'df_cleaned' est√© definido en tu script)\n",
    "# df_cleaned = pd.DataFrame({'col1': [1, 2], 'col2': ['A', 'B']}) # Ejemplo\n",
    "\n",
    "df_cleaned.to_csv(CLEAN_PATH, index=False)\n",
    "\n",
    "print(f\"Archivo guardado exitosamente en: {CLEAN_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
